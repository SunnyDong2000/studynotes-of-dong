# 基本信息
本代码使用python版本的CIFAR-10数据集，下载地址为http://www.cs.toronto.edu/~kriz/cifar.html 数据集图片示意如下：
![cifar10](https://user-images.githubusercontent.com/116711111/197977393-5531bdff-ef91-4521-afc9-a8766fb6adfe.jpg)

# 代码流程
## NearestNeighborClassifier 最近邻分类器
读取CIFAR-10数据集，得到训练集和测试集。调用train函数训练，最近邻方法的train实际上为读取所有数据。调用predict函数预测，实际上为计算每个测试集图片与每个训练集图片之间的距离，距离最短的图片标签作为测试图片的预测标签。
## k-NearestNeighborClassifier k最近邻分类
读取CIFAR-10数据集，分割训练集，得到训练集、验证集和测试集（未采用交叉验证）。调用train函数训练，最近邻方法的train实际上为读取所有数据。设置knum，调用predict函数分别预测并计算k = 1 到 k = 2 * knum - 1的所有准确率（本代码只取k为奇数）。取准确率最高的k，调用predict函数预测测试集标签。
***需要注意***的是，与NearestNeighborClassifier不同的地方在于，predict函数取距离最短的k张图片标签，再选取出现次数最多的标签作为测试图片的预测标签。
## MulticlassSupportVectorMachine 多类别支持向量机
读取CIFAR-10数据集，得到训练集和测试集。调用train函数训练，每次迭代都在测试集上保存一下loss和准确率，最后作图可视化每次迭代的变化。

CIFAR-10数据集有10个分类，每张图像的大小为32*32*3 = 3072。根据y = w * x + b可知：x大小为(3072,1)、w为(10,3072)、b和y为(3072,1)，为使权重更新只需更新一个矩阵，将w和b结合起来，即w为(10,3073)、x为(3073，1)，即对所有x后面加入一个x[3072,0] = 1，这样在矩阵乘法中w[10,3072]即为b，从而式子简化为y = w * x。
## 全连接神经网络FullConnectNeuralNetwork
检验是否理解网络中的基本变换细节，自己定义激活函数、softmax、损失函数，求梯度采用梯度的定义(笨办法)来求，未采用链式法则。数据预处理需要注意减去的均值为训练集 的均值，因为测试集数据应为未知状态。训练时计算梯度、更新权重、输出损失，测试时输出预测标签，最后计算测试集准确率。
## 卷积神经网络
在学习完cs231n后，直接开始学习pytorch，并使用pytorch完成cs231n中的cnn实现CIFAR-10数据集的分类。本代码分为两部分：

第一部分延续之前解压后读取本地数据的方法，未使用pytorch的dataset和dataloader，仅用pytorch定义了神经网络，在训练时未进行"预处理"且仅喂入单张图像，经过两轮迭代后发现测试集准确率为10.3%。一方面说明神经网络的训练确实有效果，另一方面也说明了数据预处理的重要性。

第二部分则采用pytorch(dataset和dataloader)读取CIFAR-10数据集、进行预处理，且输入batch_size = 4进行训练，发现经过两轮迭代后，测试集准确率为56%，有较大提升。

本代码神经网络由2层卷积层、2层池化层、3层全连接层组成，激活函数为Relu函数。从维度进行分析如下：

1、conv1：图像大小为(3,32,32),3代表图像的RGB三个通道，第一层卷积层有6个卷积核，卷积核大小为5*5。则输出有6层，大小为(32-5)/1 + 1= 28(即输出为(6,28,28))。计算公式为(img_size - kernel_size + 2 * padding)/stride + 1

2、pool1：输入为(6,28,28)，进行2*2最大池化，输出为(6,14,14)

3、conv2：输入为(6,14,14)，第二层卷积层有16个卷积核，卷积核大小为5*5。则则输出有16层，大小为(14-5)/1 + 1= 10，即输出为(16,10,10)

4、pool2：输入为(16,10,10)，进行2*2最大池化，输出为(16,5,5)

5、fc1：输入为(16,5,5)，以类似于SVM和全连接神经网络的方法实现，输入16*5*5个数据，输出120个数据

6、fc2：输入为(120,1)，输入120个数据，输出84个数据

7、fc3：输入为(84,1)，输入84个数据，输出10个数据
