{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08890118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2d4a62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "#定义一个叫做Net的类，继承自父类nn.Module\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        #super实现对父类的同名函数的继承和改写\n",
    "# torch.nn.Conv2d(in_channels,out_channels,kernel_size,stride = 1,padding = 0,dilation = 1,groups = 1,bias = True,padding_mode = 'zeros')\n",
    "        #in_channels：输入图像的通道数(RGB为3) out_channels：输出图像的通道数，即卷积核的个数 kernel_size：卷积核的大小\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) #输入灰度图、6个卷积核、卷积核大小为5*5\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) #输入6通道图像、16个卷积核、卷积核大小为5*5\n",
    "        #定义全连接层: y = Wx + b\n",
    "        #nn.Linear(in_features,out_features,bias=True)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) #全连接层输入有16*5*5数据，输出为120维数据\n",
    "        self.fc2 = nn.Linear(120, 84) #全连接层输入有120维，输出为84维数据\n",
    "        self.fc3 = nn.Linear(84, 10)#全连接层输入有84维，输出为10维数据\n",
    "\n",
    "    def forward(self, x):\n",
    "        #torch.nn.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, ceil_mode=False, return_indices=False)\n",
    "        #F.max_pool2d：最大池化层\n",
    "        #卷积、Relu激活、2*2池化层池化\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 池化核大小为正方形时，可以用一个数字代替\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #改变数据维度，将数据展开\n",
    "        #x = x.view(-1, self.num_flat_features(x))#调用自己定义的函数展开数据\n",
    "        x = x.view(-1, x.size()[1:].numel())#与函数等价，但不用定义函数，代码更简洁\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    #定义一个函数，将输入数据展开\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()#实例化类Net\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c0fd82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0081,  0.0323,  0.0311,  0.0622,  0.0549, -0.0162, -0.0463,  0.1097,\n",
      "         -0.0039,  0.0569]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32) #产生一个32*32的随机数，作为灰度图像\n",
    "out = net(input) #调用forward()函数计算输出\n",
    "#需要注意的是，Net()类继承自nn.Module，nn.Module的初始化函数会调用forward函数\n",
    "\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3bdb1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#先清理梯度中原来的值，在调用backward函数计算梯度。否则会在原来的值上加上新的值。\n",
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18060c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4093, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = torch.randn(10)  #随机十个值作为真实标签\n",
    "target = target.view(1, -1)  #使target和output的shape相同，-1的作用是自动匹配维度\n",
    "criterion = nn.MSELoss() #确定损失函数\n",
    "loss = criterion(output, target) #计算预测output和标签target之间的损失\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd77403",
   "metadata": {},
   "source": [
    "反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352f9cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad after backward\n",
      "tensor([-0.0132,  0.0040, -0.0251,  0.0121,  0.0254, -0.0058])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()     # 清除梯度\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8a4ef",
   "metadata": {},
   "source": [
    "更新权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4364ef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b904c2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用python简单实现\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df8d2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用torch工具包来更新权重\n",
    "import torch.optim as optim\n",
    "\n",
    "#构建优化器optimizer\n",
    "#优化器详见：https://blog.csdn.net/qq_34690929/article/details/79932416\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "#每一次训练数据,执行以下操作\n",
    "optimizer.zero_grad()#清零梯度\n",
    "output = net(input)#计算输出\n",
    "loss = criterion(output, target)#计算loss\n",
    "loss.backward()#计算梯度\n",
    "optimizer.step()#更新权重"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
